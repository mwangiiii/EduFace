{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb803301",
   "metadata": {},
   "source": [
    "# EDUFACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd233fba",
   "metadata": {},
   "source": [
    "-    this is a facial recognition system that will be integrated together with an LMS system to record student's attendance using facial recognition technology integrated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50233524",
   "metadata": {},
   "source": [
    "### INSTALLING THE DEPENDENCIES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73b16457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\projects\\eduface project\\venv\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: opencv-python in c:\\projects\\eduface project\\venv\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: matplotlib in c:\\projects\\eduface project\\venv\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: packaging in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (1.73.1)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: optree in c:\\projects\\eduface project\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: namex in c:\\projects\\eduface project\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: rich in c:\\projects\\eduface project\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow opencv-python matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5889d05",
   "metadata": {},
   "source": [
    "### IMPORTING THE DEPENDENCIES.\n",
    "\n",
    "- we will install the standard dependencies first then install the tensor-flow dependencies later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11097e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#isntalling standard dependencies.\n",
    "\n",
    "import cv2 #used to import open-cv into the noteboook\n",
    "import os #OS system library that is needed when creating our Directories. it hence abstracts our operating system from our python\n",
    "import random #used if we are generating new data.\n",
    "import numpy as np #used when working with mathematical operations.\n",
    "from matplotlib import pyplot as plt #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c225b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will now import tensorflow dependencies that will use tensorflow functional API components.\n",
    "from tensorflow.keras.models import Model #this is one of most important layers since when creating a model we will need this when declaring Model(Inputs=>>> Output=>>) it enables us classify betwen output and input.\n",
    "#our model will  look like: Model(inputs=[inputImage, verificationImage] output=[1,0]) this is what the model class helps us to do.\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten #model is a whole lot of abig class and we need these specific classes when building our model\n",
    "#1. layer class is a high level class that helps you define a custom neural network layer\n",
    "#2. conv2d - allows us to perform convolutions\n",
    "#3. dense allows us to get a fully connected layer\n",
    "#4. maxpooling2D allows us to pull our layers together and combine the information that we have through a condition\n",
    "#5. Input allows us to identofy what we are passing through to our model.\n",
    "#6. flatten takes the information from  a previous layer and flatten it into a single dimension\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5161f99",
   "metadata": {},
   "source": [
    "### Set GPU growth.\n",
    "- here we are going to limit our amount of VRAM given to tensorflow hence you will keep on ending up to \"out of memory error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63014504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "print(\"Number of GPUs available:\", len(gpus))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9174ac28",
   "metadata": {},
   "source": [
    "### Setting up folder structure.\n",
    "- we are going to set up the directories for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4cea780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_Path=os.path.join('data', 'positive')\n",
    "NEG_Path=os.path.join('data', 'negative')\n",
    "ANC_Path=os.path.join('data', 'anchor')\n",
    "\n",
    "#the above create the paths for the directories.\n",
    "\n",
    "#os.path.join joins diferent directroy together to be able to get a full file path and you will be able to get  forward backslash or backward slash depeding on the Os that you are using\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3936d050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Directories created/verified:\n",
      "   Positive: C:\\Projects\\EDUFACE PROJECT\\data\\positive\n",
      "   Negative: C:\\Projects\\EDUFACE PROJECT\\data\\negative\n",
      "   Anchor: C:\\Projects\\EDUFACE PROJECT\\data\\anchor\n",
      "\n",
      "üîç Verifying paths exist:\n",
      "   Positive exists: True\n",
      "   Negative exists: True\n",
      "   Anchor exists: True\n"
     ]
    }
   ],
   "source": [
    "### Setting up folder structure.\n",
    "# we are going to set up the directories for positive, negative, and anchor images\n",
    "\n",
    "import os\n",
    "\n",
    "# Define base path for consistency\n",
    "BASE_PATH = r'C:\\Projects\\EDUFACE PROJECT'\n",
    "DATA_PATH = os.path.join(BASE_PATH, 'data')\n",
    "\n",
    "# CORRECTED: Use the data subdirectories consistently\n",
    "POS_Path = os.path.join(DATA_PATH, 'positive')\n",
    "NEG_Path = os.path.join(DATA_PATH, 'negative')\n",
    "ANC_Path = os.path.join(DATA_PATH, 'anchor')\n",
    "\n",
    "# Make the actual directories specified with the above paths\n",
    "# exist_ok=True prevents errors if directories already exist\n",
    "os.makedirs(POS_Path, exist_ok=True)\n",
    "os.makedirs(NEG_Path, exist_ok=True)\n",
    "os.makedirs(ANC_Path, exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Directories created/verified:\")\n",
    "print(f\"   Positive: {POS_Path}\")\n",
    "print(f\"   Negative: {NEG_Path}\")\n",
    "print(f\"   Anchor: {ANC_Path}\")\n",
    "\n",
    "# Verify the paths are correct\n",
    "print(f\"\\nüîç Verifying paths exist:\")\n",
    "print(f\"   Positive exists: {os.path.exists(POS_Path)}\")\n",
    "print(f\"   Negative exists: {os.path.exists(NEG_Path)}\")\n",
    "print(f\"   Anchor exists: {os.path.exists(ANC_Path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f601765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found .tgz file at: C:\\Projects\\EDUFACE PROJECT\\lfw-funneled.tgz\n",
      "File size: 232.07 MB\n",
      "\n",
      "üîÑ Extracting dataset to: C:\\Projects\\EDUFACE PROJECT\\data\\negative\n",
      "Archive contains 18994 files/folders\n",
      "First few items in archive:\n",
      "  - lfw_funneled\n",
      "  - lfw_funneled/George_HW_Bush\n",
      "  - lfw_funneled/George_HW_Bush/George_HW_Bush_0001.jpg\n",
      "  - lfw_funneled/George_HW_Bush/George_HW_Bush_0002.jpg\n",
      "  - lfw_funneled/George_HW_Bush/George_HW_Bush_0003.jpg\n",
      "Archive contains 18994 files/folders\n",
      "First few items in archive:\n",
      "  - lfw_funneled\n",
      "  - lfw_funneled/George_HW_Bush\n",
      "  - lfw_funneled/George_HW_Bush/George_HW_Bush_0001.jpg\n",
      "  - lfw_funneled/George_HW_Bush/George_HW_Bush_0002.jpg\n",
      "  - lfw_funneled/George_HW_Bush/George_HW_Bush_0003.jpg\n",
      "‚úÖ Dataset extracted successfully!\n",
      "\n",
      "üîç Searching for dataset root...\n",
      "‚úÖ Found dataset at: C:\\Projects\\EDUFACE PROJECT\\data\\negative\\lfw_funneled\n",
      "\n",
      "üìä Dataset Information:\n",
      "‚úÖ Dataset extracted successfully!\n",
      "\n",
      "üîç Searching for dataset root...\n",
      "‚úÖ Found dataset at: C:\\Projects\\EDUFACE PROJECT\\data\\negative\\lfw_funneled\n",
      "\n",
      "üìä Dataset Information:\n",
      "Number of persons: 5749\n",
      "First 10 persons: ['Aaron_Eckhart', 'Aaron_Guiel', 'Aaron_Patterson', 'Aaron_Peirsol', 'Aaron_Pena', 'Aaron_Sorkin', 'Aaron_Tippin', 'Abbas_Kiarostami', 'Abba_Eban', 'Abdel_Aziz_Al-Hakim']\n",
      "Sample: First 10 persons have 14 images\n",
      "Example: Aaron_Eckhart/Aaron_Eckhart_0001.jpg\n",
      "\n",
      "‚úÖ Dataset ready at: C:\\Projects\\EDUFACE PROJECT\\data\\negative\\lfw_funneled\n",
      "Number of persons: 5749\n",
      "First 10 persons: ['Aaron_Eckhart', 'Aaron_Guiel', 'Aaron_Patterson', 'Aaron_Peirsol', 'Aaron_Pena', 'Aaron_Sorkin', 'Aaron_Tippin', 'Abbas_Kiarostami', 'Abba_Eban', 'Abdel_Aziz_Al-Hakim']\n",
      "Sample: First 10 persons have 14 images\n",
      "Example: Aaron_Eckhart/Aaron_Eckhart_0001.jpg\n",
      "\n",
      "‚úÖ Dataset ready at: C:\\Projects\\EDUFACE PROJECT\\data\\negative\\lfw_funneled\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "# 1. Path to your LFW .tgz file\n",
    "tgz_path = r\"C:\\Projects\\EDUFACE PROJECT\\lfw-funneled.tgz\"\n",
    "\n",
    "# 2. Extraction path - into the negative folder\n",
    "extract_path = r\"C:\\Projects\\EDUFACE PROJECT\\data\\negative\"\n",
    "\n",
    "# 3. Validate the .tgz file exists\n",
    "if not os.path.isfile(tgz_path):\n",
    "    raise FileNotFoundError(f\"Error: The file '{tgz_path}' does not exist.\")\n",
    "\n",
    "print(f\"Found .tgz file at: {tgz_path}\")\n",
    "print(f\"File size: {os.path.getsize(tgz_path) / (1024*1024):.2f} MB\")\n",
    "\n",
    "# 4. Create extraction directory\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    print(f\"\\nüîÑ Extracting dataset to: {extract_path}\")\n",
    "    with tarfile.open(tgz_path, 'r:gz') as tar:\n",
    "        # List first few members to see the structure\n",
    "        members = tar.getmembers()\n",
    "        print(f\"Archive contains {len(members)} files/folders\")\n",
    "        print(\"First few items in archive:\")\n",
    "        for member in members[:5]:\n",
    "            print(f\"  - {member.name}\")\n",
    "        \n",
    "        # Extract all\n",
    "        tar.extractall(path=extract_path)\n",
    "    print(\"‚úÖ Dataset extracted successfully!\")\n",
    "    \n",
    "except PermissionError:\n",
    "    raise PermissionError(f\"Permission denied. Try running as administrator.\")\n",
    "except tarfile.ReadError:\n",
    "    raise ValueError(f\"'{tgz_path}' is not a valid .tgz file.\")\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Extraction failed: {str(e)}\")\n",
    "\n",
    "# 5. Find the actual root directory\n",
    "print(\"\\nüîç Searching for dataset root...\")\n",
    "possible_roots = [\n",
    "    os.path.join(extract_path, \"lfw_funneled\"),\n",
    "    os.path.join(extract_path, \"lfw-funneled\"),\n",
    "    os.path.join(extract_path, \"lfw\"),\n",
    "]\n",
    "\n",
    "lfw_root = None\n",
    "for root in possible_roots:\n",
    "    if os.path.exists(root) and os.path.isdir(root):\n",
    "        lfw_root = root\n",
    "        print(f\"‚úÖ Found dataset at: {lfw_root}\")\n",
    "        break\n",
    "\n",
    "if lfw_root is None:\n",
    "    # List what was actually extracted\n",
    "    print(f\"\\n‚ö†Ô∏è Could not find expected folders. Contents of {extract_path}:\")\n",
    "    for item in os.listdir(extract_path):\n",
    "        item_path = os.path.join(extract_path, item)\n",
    "        item_type = \"DIR\" if os.path.isdir(item_path) else \"FILE\"\n",
    "        print(f\"  - [{item_type}] {item}\")\n",
    "    print(\"\\nPlease check the extracted contents above.\")\n",
    "else:\n",
    "    # 6. Analyze the dataset structure\n",
    "    print(\"\\nüìä Dataset Information:\")\n",
    "    person_folders = [d for d in os.listdir(lfw_root) if os.path.isdir(os.path.join(lfw_root, d))]\n",
    "    print(f\"Number of persons: {len(person_folders)}\")\n",
    "    print(f\"First 10 persons: {person_folders[:10]}\")\n",
    "    \n",
    "    # Count total images\n",
    "    total_images = 0\n",
    "    sample_person = None\n",
    "    for person in person_folders[:10]:  # Check first 10 persons\n",
    "        person_path = os.path.join(lfw_root, person)\n",
    "        images = [f for f in os.listdir(person_path) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        total_images += len(images)\n",
    "        if not sample_person and images:\n",
    "            sample_person = (person, images[0])\n",
    "    \n",
    "    print(f\"Sample: First 10 persons have {total_images} images\")\n",
    "    if sample_person:\n",
    "        print(f\"Example: {sample_person[0]}/{sample_person[1]}\")\n",
    "    print(f\"\\n‚úÖ Dataset ready at: {lfw_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e26596",
   "metadata": {},
   "source": [
    "### moving the lfw data into the data/negative data repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90f10649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Directories created/verified:\n",
      "   Positive: C:\\Projects\\EDUFACE PROJECT\\data\\positive\n",
      "   Negative: C:\\Projects\\EDUFACE PROJECT\\data\\negative\n",
      "   Anchor: C:\\Projects\\EDUFACE PROJECT\\data\\anchor\n",
      "\n",
      "üîç Verifying paths exist:\n",
      "   Positive exists: True\n",
      "   Negative exists: True\n",
      "   Anchor exists: True\n"
     ]
    }
   ],
   "source": [
    "### Setting up folder structure.\n",
    "# we are going to set up the directories for positive, negative, and anchor images\n",
    "\n",
    "import os\n",
    "\n",
    "# Define base path for consistency\n",
    "BASE_PATH = r'C:\\Projects\\EDUFACE PROJECT'\n",
    "DATA_PATH = os.path.join(BASE_PATH, 'data')\n",
    "\n",
    "# CORRECTED: Use the data subdirectories consistently\n",
    "POS_Path = os.path.join(DATA_PATH, 'positive')\n",
    "NEG_Path = os.path.join(DATA_PATH, 'negative')\n",
    "ANC_Path = os.path.join(DATA_PATH, 'anchor')\n",
    "\n",
    "# Make the actual directories specified with the above paths\n",
    "# exist_ok=True prevents errors if directories already exist\n",
    "os.makedirs(POS_Path, exist_ok=True)\n",
    "os.makedirs(NEG_Path, exist_ok=True)\n",
    "os.makedirs(ANC_Path, exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Directories created/verified:\")\n",
    "print(f\"   Positive: {POS_Path}\")\n",
    "print(f\"   Negative: {NEG_Path}\")\n",
    "print(f\"   Anchor: {ANC_Path}\")\n",
    "\n",
    "# Verify the paths are correct\n",
    "print(f\"\\nüîç Verifying paths exist:\")\n",
    "print(f\"   Positive exists: {os.path.exists(POS_Path)}\")\n",
    "print(f\"   Negative exists: {os.path.exists(NEG_Path)}\")\n",
    "print(f\"   Anchor exists: {os.path.exists(ANC_Path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319024c",
   "metadata": {},
   "source": [
    "## collect Positves and Anchors.\n",
    "- we are going to use opencv and we are going to collect those images down nd save them down. the sime of the images to be collected are going to be 250 pixels by 250 pixels.\n",
    "\n",
    "-   by default, when using webcam, the resolution of the images might be a little different so we should ensure that we are collecting images of that size because the sizes from the training dataset are of the same size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba77639f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Images will be saved to:\n",
      "   Anchor: C:\\Projects\\EDUFACE PROJECT\\data\\anchor\n",
      "   Positive: C:\\Projects\\EDUFACE PROJECT\\data\\positive\n",
      "\n",
      "Loading face detection cascades...\n",
      "‚úÖ Loaded frontal cascade\n",
      "‚úÖ Loaded profile cascade\n",
      "‚úÖ Loaded frontal_alt cascade\n",
      "‚úÖ Loaded frontal_alt2 cascade\n",
      "Testing Index 0, Backend default: Opened=True, Frame captured=True\n",
      "‚úÖ Webcam found at index 0 (backend: default)\n",
      "\n",
      "üëâ Using source: index 0\n",
      "üëâ A video preview window will appear.\n",
      "üëâ Press 'a' to switch to ANCHOR mode\n",
      "üëâ Press 'p' to switch to POSITIVE mode\n",
      "üëâ Press and hold 'c' to capture images continuously (every 0.2s).\n",
      "üëâ The system will detect faces from multiple angles (front, profile, etc.)\n",
      "üëâ Release 'c' to pause. Press and hold again to continue capturing.\n",
      "üëâ Press 'q' to quit and save all captured images.\n",
      "‚ö†Ô∏è Images will be cropped to detected faces and saved with angle information.\n",
      "\n",
      "üí° TIP: Move your head to different angles while capturing for a better dataset!\n",
      "   - Look straight at camera (frontal)\n",
      "   - Turn left and right (profiles)\n",
      "   - Slightly tilt up and down\n",
      "\n",
      "Testing Index 0, Backend default: Opened=True, Frame captured=True\n",
      "‚úÖ Webcam found at index 0 (backend: default)\n",
      "\n",
      "üëâ Using source: index 0\n",
      "üëâ A video preview window will appear.\n",
      "üëâ Press 'a' to switch to ANCHOR mode\n",
      "üëâ Press 'p' to switch to POSITIVE mode\n",
      "üëâ Press and hold 'c' to capture images continuously (every 0.2s).\n",
      "üëâ The system will detect faces from multiple angles (front, profile, etc.)\n",
      "üëâ Release 'c' to pause. Press and hold again to continue capturing.\n",
      "üëâ Press 'q' to quit and save all captured images.\n",
      "‚ö†Ô∏è Images will be cropped to detected faces and saved with angle information.\n",
      "\n",
      "üí° TIP: Move your head to different angles while capturing for a better dataset!\n",
      "   - Look straight at camera (frontal)\n",
      "   - Turn left and right (profiles)\n",
      "   - Slightly tilt up and down\n",
      "\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_front2_30_f17e6b5e.jpg (Type: frontal_alt2, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_front2_30_f17e6b5e.jpg (Type: frontal_alt2, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_front_31_825f6253.jpg (Type: frontal, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_front_31_825f6253.jpg (Type: frontal, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_32_fd18fc45.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_32_fd18fc45.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_33_62fca290.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_33_62fca290.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_34_befa307c.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_34_befa307c.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_35_832555b3.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_35_832555b3.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_36_8b824cc9.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_36_8b824cc9.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_37_4b1c3c69.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_37_4b1c3c69.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_38_9d65d42a.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_38_9d65d42a.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_39_316db3d4.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_39_316db3d4.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_40_b24d06b4.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_40_b24d06b4.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_41_51c950bb.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_41_51c950bb.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_42_ee3904d2.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_42_ee3904d2.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_43_c53e370c.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_43_c53e370c.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_44_61213f89.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_44_61213f89.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_45_1e5de627.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_45_1e5de627.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_46_549eab3c.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_46_549eab3c.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_47_da5c4c3d.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_profile_47_da5c4c3d.jpg (Type: profile, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_front2_48_0a9d595d.jpg (Type: frontal_alt2, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_front2_48_0a9d595d.jpg (Type: frontal_alt2, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_front_49_4d412143.jpg (Type: frontal_alt, Mode: positive)\n",
      "‚úÖ Saved C:\\Projects\\EDUFACE PROJECT\\data\\positive\\dennis_151354_front_49_4d412143.jpg (Type: frontal_alt, Mode: positive)\n",
      "\n",
      "üëã Exiting capture...\n",
      "\n",
      "üëã Exiting capture...\n",
      "\n",
      "üëã Capture session complete!\n",
      "üìÅ Images saved in:\n",
      "   üìÅ Anchor folder: C:\\Projects\\EDUFACE PROJECT\\data\\anchor (39 images)\n",
      "   üìÅ Positive folder: C:\\Projects\\EDUFACE PROJECT\\data\\positive (49 images)\n",
      "\n",
      "üìä Dataset Summary:\n",
      "   Anchor:\n",
      "     - Frontal: 8 images\n",
      "     - Profile: 31 images\n",
      "   Positive:\n",
      "     - Frontal: 12 images\n",
      "     - Profile: 37 images\n",
      "\n",
      "üëã Capture session complete!\n",
      "üìÅ Images saved in:\n",
      "   üìÅ Anchor folder: C:\\Projects\\EDUFACE PROJECT\\data\\anchor (39 images)\n",
      "   üìÅ Positive folder: C:\\Projects\\EDUFACE PROJECT\\data\\positive (49 images)\n",
      "\n",
      "üìä Dataset Summary:\n",
      "   Anchor:\n",
      "     - Frontal: 8 images\n",
      "     - Profile: 31 images\n",
      "   Positive:\n",
      "     - Frontal: 12 images\n",
      "     - Profile: 37 images\n"
     ]
    }
   ],
   "source": [
    "## collect Positves and Anchors.\n",
    "# we are going to use opencv and we are going to collect those images down and save them down. \n",
    "# the size of the images to be collected are going to be 250 pixels by 250 pixels.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import platform\n",
    "import uuid\n",
    "\n",
    "def find_working_webcam(max_index=10):\n",
    "    \"\"\"Try to find a working webcam by testing indices with optional backend.\"\"\"\n",
    "    backends = [None]  # Default backend\n",
    "    if platform.system() == \"Windows\":\n",
    "        backends.append(cv2.CAP_DSHOW)  # DirectShow\n",
    "        backends.append(cv2.CAP_MSMF)   # Windows Media Foundation\n",
    "    elif platform.system() == \"Linux\":\n",
    "        backends.append(cv2.CAP_V4L2)   # V4L2\n",
    "\n",
    "    for backend in backends:\n",
    "        for index in range(max_index):\n",
    "            cap = cv2.VideoCapture(index, backend) if backend else cv2.VideoCapture(index)\n",
    "            if cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                print(f\"Testing Index {index}, Backend {backend if backend else 'default'}: Opened={cap.isOpened()}, Frame captured={ret}\")\n",
    "                if ret:\n",
    "                    print(f\"‚úÖ Webcam found at index {index} (backend: {backend if backend else 'default'})\")\n",
    "                    return cap, index\n",
    "                cap.release()\n",
    "    return None, None\n",
    "\n",
    "# Fallback: Use a video file or static image for debugging if no webcam is found\n",
    "fallback_source = os.path.join(BASE_PATH, \"test_video.mp4\")\n",
    "\n",
    "# Ask for student details\n",
    "student_name = input(\"Enter student name: \").strip().replace(\" \", \"_\")\n",
    "student_id = input(\"Enter school ID: \").strip()\n",
    "\n",
    "# Validate student_id for safe file naming\n",
    "invalid_chars = '<>:\"/\\\\|?*'\n",
    "for char in invalid_chars:\n",
    "    student_id = student_id.replace(char, \"_\")\n",
    "\n",
    "# Use the data/positive and data/anchor directories we created earlier\n",
    "print(f\"\\nüìÅ Images will be saved to:\")\n",
    "print(f\"   Anchor: {ANC_Path}\")\n",
    "print(f\"   Positive: {POS_Path}\")\n",
    "\n",
    "# Initialize capture type\n",
    "capture_type = \"positive\"  # Default capture type\n",
    "\n",
    "# Function to get next count for a specific folder and type\n",
    "def get_next_count(folder_path, student_name, student_id):\n",
    "    \"\"\"Get the next count number for files in the specified folder\"\"\"\n",
    "    existing_files = glob.glob(os.path.join(folder_path, f\"{student_name}_{student_id}_*.jpg\"))\n",
    "    if existing_files:\n",
    "        counts = []\n",
    "        for f in existing_files:\n",
    "            try:\n",
    "                basename = os.path.basename(f)\n",
    "                # Extract number from filename\n",
    "                parts = basename.replace(f\"{student_name}_{student_id}_\", \"\").replace(\".jpg\", \"\")\n",
    "                # Extract the last number before UUID\n",
    "                parts_split = parts.split('_')\n",
    "                for part in parts_split:\n",
    "                    if part.isdigit():\n",
    "                        counts.append(int(part))\n",
    "            except:\n",
    "                continue\n",
    "        return max(counts) + 1 if counts else 1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Initialize counters for each folder\n",
    "anchor_count = get_next_count(ANC_Path, student_name, student_id)\n",
    "positive_count = get_next_count(POS_Path, student_name, student_id)\n",
    "\n",
    "# Load multiple Haar Cascades for different face orientations\n",
    "cascades = {}\n",
    "cascade_files = {\n",
    "    'frontal': 'haarcascade_frontalface_default.xml',\n",
    "    'profile': 'haarcascade_profileface.xml',\n",
    "    'frontal_alt': 'haarcascade_frontalface_alt.xml',\n",
    "    'frontal_alt2': 'haarcascade_frontalface_alt2.xml'\n",
    "}\n",
    "\n",
    "print(\"\\nLoading face detection cascades...\")\n",
    "for cascade_name, cascade_file in cascade_files.items():\n",
    "    cascade_path = cv2.data.haarcascades + cascade_file\n",
    "    cascade = cv2.CascadeClassifier(cascade_path)\n",
    "    if not cascade.empty():\n",
    "        cascades[cascade_name] = cascade\n",
    "        print(f\"‚úÖ Loaded {cascade_name} cascade\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Could not load {cascade_name} cascade from {cascade_path}\")\n",
    "\n",
    "if not cascades:\n",
    "    raise ValueError(\"Error: Could not load any Haar Cascade classifiers.\")\n",
    "\n",
    "def detect_faces_multi_angle(gray_frame):\n",
    "    \"\"\"Detect faces using multiple cascades for different angles\"\"\"\n",
    "    all_faces = []\n",
    "    detected_types = []\n",
    "    \n",
    "    for cascade_name, cascade in cascades.items():\n",
    "        # Different parameters for different cascade types\n",
    "        if 'profile' in cascade_name:\n",
    "            faces = cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=4, minSize=(30, 30))\n",
    "        else:\n",
    "            faces = cascade.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "        \n",
    "        for face in faces:\n",
    "            all_faces.append(face)\n",
    "            detected_types.append(cascade_name)\n",
    "    \n",
    "    return all_faces, detected_types\n",
    "\n",
    "def remove_overlapping_faces(faces, detected_types, overlap_threshold=0.3):\n",
    "    \"\"\"Remove overlapping face detections to avoid duplicates\"\"\"\n",
    "    if len(faces) <= 1:\n",
    "        return faces, detected_types\n",
    "    \n",
    "    def calculate_overlap(box1, box2):\n",
    "        x1, y1, w1, h1 = box1\n",
    "        x2, y2, w2, h2 = box2\n",
    "        \n",
    "        # Calculate intersection area\n",
    "        x_overlap = max(0, min(x1 + w1, x2 + w2) - max(x1, x2))\n",
    "        y_overlap = max(0, min(y1 + h1, y2 + h2) - max(y1, y2))\n",
    "        intersection = x_overlap * y_overlap\n",
    "        \n",
    "        # Calculate union area\n",
    "        area1 = w1 * h1\n",
    "        area2 = w2 * h2\n",
    "        union = area1 + area2 - intersection\n",
    "        \n",
    "        return intersection / union if union > 0 else 0\n",
    "    \n",
    "    # Keep track of which faces to keep\n",
    "    keep = [True] * len(faces)\n",
    "    \n",
    "    for i in range(len(faces)):\n",
    "        if not keep[i]:\n",
    "            continue\n",
    "        for j in range(i + 1, len(faces)):\n",
    "            if not keep[j]:\n",
    "                continue\n",
    "            \n",
    "            overlap = calculate_overlap(faces[i], faces[j])\n",
    "            if overlap > overlap_threshold:\n",
    "                # Keep the larger face detection\n",
    "                area1 = faces[i][2] * faces[i][3]\n",
    "                area2 = faces[j][2] * faces[j][3]\n",
    "                if area1 >= area2:\n",
    "                    keep[j] = False\n",
    "                else:\n",
    "                    keep[i] = False\n",
    "                    break\n",
    "    \n",
    "    filtered_faces = [faces[i] for i in range(len(faces)) if keep[i]]\n",
    "    filtered_types = [detected_types[i] for i in range(len(detected_types)) if keep[i]]\n",
    "    \n",
    "    return filtered_faces, filtered_types\n",
    "\n",
    "# Initialize webcam\n",
    "cap, webcam_index = find_working_webcam(max_index=10)\n",
    "if cap is None:\n",
    "    print(\"‚ö†Ô∏è No webcam found. Falling back to test source (video/image) for debugging.\")\n",
    "    if os.path.exists(fallback_source):\n",
    "        cap = cv2.VideoCapture(fallback_source)\n",
    "        webcam_index = \"fallback\"\n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Error: Could not open fallback source '{fallback_source}'.\")\n",
    "        print(f\"Using fallback source: {fallback_source}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Error: No webcam found, and fallback source '{fallback_source}' does not exist.\")\n",
    "\n",
    "print(f\"\\nüëâ Using source: index {webcam_index if webcam_index != 'fallback' else fallback_source}\")\n",
    "print(\"üëâ A video preview window will appear.\")\n",
    "print(\"üëâ Press 'a' to switch to ANCHOR mode\")\n",
    "print(\"üëâ Press 'p' to switch to POSITIVE mode\")\n",
    "print(\"üëâ Press and hold 'c' to capture images continuously (every 0.2s).\")\n",
    "print(\"üëâ The system will detect faces from multiple angles (front, profile, etc.)\")\n",
    "print(\"üëâ Release 'c' to pause. Press and hold again to continue capturing.\")\n",
    "print(\"üëâ Press 'q' to quit and save all captured images.\")\n",
    "print(\"‚ö†Ô∏è Images will be cropped to detected faces and saved with angle information.\\n\")\n",
    "print(\"üí° TIP: Move your head to different angles while capturing for a better dataset!\")\n",
    "print(\"   - Look straight at camera (frontal)\")\n",
    "print(\"   - Turn left and right (profiles)\")\n",
    "print(\"   - Slightly tilt up and down\\n\")\n",
    "\n",
    "# Flag to control capturing\n",
    "is_capturing = False\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            if webcam_index == \"fallback\" and cap.get(cv2.CAP_PROP_POS_FRAMES) >= cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Loop video\n",
    "                continue\n",
    "            print(\"Error: Failed to capture frame from source.\")\n",
    "            break\n",
    "\n",
    "        # Convert to grayscale for face detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces from multiple angles\n",
    "        faces, face_types = detect_faces_multi_angle(gray)\n",
    "        \n",
    "        # Remove overlapping detections\n",
    "        faces, face_types = remove_overlapping_faces(faces, face_types)\n",
    "\n",
    "        # Draw rectangles around detected faces with different colors for different types\n",
    "        colors = {\n",
    "            'frontal': (0, 255, 0),      # Green for frontal\n",
    "            'profile': (255, 0, 0),      # Blue for profile\n",
    "            'frontal_alt': (0, 255, 255), # Yellow for frontal alt\n",
    "            'frontal_alt2': (255, 0, 255) # Magenta for frontal alt2\n",
    "        }\n",
    "        \n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "            face_type = face_types[i] if i < len(face_types) else 'frontal'\n",
    "            color = colors.get(face_type, (0, 255, 0))\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "            \n",
    "            # Add label showing the detection type\n",
    "            label = face_type.replace('_', ' ').title()\n",
    "            cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        # Add status text\n",
    "        status_text = f\"Mode: {capture_type.upper()} | Faces: {len(faces)} | {'CAPTURING' if is_capturing else 'PAUSED'}\"\n",
    "        cv2.putText(frame, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 1)\n",
    "        \n",
    "        # Add counts\n",
    "        count_text = f\"Anchor: {anchor_count-1} | Positive: {positive_count-1}\"\n",
    "        cv2.putText(frame, count_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, count_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Multi-Angle Face Capture - 'a' anchor, 'p' positive, 'c' capture, 'q' quit\", frame)\n",
    "\n",
    "        # Check for keypress\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # Handle mode switching\n",
    "        if key == ord('a'):\n",
    "            capture_type = 'anchor'\n",
    "            print(f\"üîÑ Switched to ANCHOR capture mode\")\n",
    "        elif key == ord('p'):\n",
    "            capture_type = \"positive\"\n",
    "            print(f\"üîÑ Switched to POSITIVE capture mode\")\n",
    "        elif key == ord('c'):\n",
    "            is_capturing = True\n",
    "        elif key == 255:  # No key pressed (equivalent to releasing 'c')\n",
    "            is_capturing = False\n",
    "        elif key == ord('q'):\n",
    "            print(\"\\nüëã Exiting capture...\")\n",
    "            break\n",
    "\n",
    "        # Capture and save faces if 'c' is held\n",
    "        if is_capturing and faces:\n",
    "            # Pick folder and counter based on current capture type\n",
    "            if capture_type == \"anchor\":\n",
    "                save_folder = ANC_Path\n",
    "                current_count = anchor_count\n",
    "            else:\n",
    "                save_folder = POS_Path\n",
    "                current_count = positive_count\n",
    "            \n",
    "            for i, (x, y, w, h) in enumerate(faces):\n",
    "                face_crop = frame[y:y+h, x:x+w]\n",
    "                \n",
    "                # Determine angle/type for filename\n",
    "                face_type = face_types[i] if i < len(face_types) else 'frontal'\n",
    "                angle_name = face_type.replace('frontal', 'front').replace('_alt', '').replace('_alt2', '')\n",
    "                \n",
    "                # Create filename with UUID for uniqueness\n",
    "                unique_id = str(uuid.uuid4())[:8]  # Use first 8 characters of UUID\n",
    "                filename = os.path.join(save_folder, f\"{student_name}_{student_id}_{angle_name}_{current_count}_{unique_id}.jpg\")\n",
    "                \n",
    "                # Resize face crop to standard size (250x250 as specified)\n",
    "                face_resized = cv2.resize(face_crop, (250, 250))\n",
    "                \n",
    "                cv2.imwrite(filename, face_resized)\n",
    "                print(f\"‚úÖ Saved {filename} (Type: {face_type}, Mode: {capture_type})\")\n",
    "                \n",
    "                # Increment the appropriate counter\n",
    "                if capture_type == \"anchor\":\n",
    "                    anchor_count += 1\n",
    "                else:\n",
    "                    positive_count += 1\n",
    "            \n",
    "            time.sleep(0.2)  # Capture every 0.2 seconds to avoid oversaving\n",
    "\n",
    "finally:\n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Final statistics\n",
    "total_anchor = len(glob.glob(os.path.join(ANC_Path, \"*.jpg\")))\n",
    "total_positive = len(glob.glob(os.path.join(POS_Path, \"*.jpg\")))\n",
    "\n",
    "print(f\"\\nüëã Capture session complete!\")\n",
    "print(f\"üìÅ Images saved in:\")\n",
    "print(f\"   üìÅ Anchor folder: {ANC_Path} ({total_anchor} images)\")\n",
    "print(f\"   üìÅ Positive folder: {POS_Path} ({total_positive} images)\")\n",
    "\n",
    "print(\"\\nüìä Dataset Summary:\")\n",
    "# Count different types of images in each folder\n",
    "for folder_name, folder_path in [(\"Anchor\", ANC_Path), (\"Positive\", POS_Path)]:\n",
    "    angle_counts = {}\n",
    "    for f in glob.glob(os.path.join(folder_path, \"*.jpg\")):\n",
    "        basename = os.path.basename(f)\n",
    "        if 'front' in basename:\n",
    "            angle_counts['frontal'] = angle_counts.get('frontal', 0) + 1\n",
    "        elif 'profile' in basename:\n",
    "            angle_counts['profile'] = angle_counts.get('profile', 0) + 1\n",
    "        else:\n",
    "            angle_counts['other'] = angle_counts.get('other', 0) + 1\n",
    "    \n",
    "    print(f\"   {folder_name}:\")\n",
    "    for angle, count in angle_counts.items():\n",
    "        print(f\"     - {angle.title()}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cc3a65",
   "metadata": {},
   "source": [
    "### Load and Preprocess images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a77e378",
   "metadata": {},
   "source": [
    "#### Get image Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "684bc739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Restoring negative folder structure...\n",
      "   Restored 100 images...\n",
      "   Restored 200 images...\n",
      "   Restored 100 images...\n",
      "   Restored 200 images...\n",
      "   Restored 300 images...\n",
      "   Restored 400 images...\n",
      "   Restored 300 images...\n",
      "   Restored 400 images...\n",
      "   Restored 500 images...\n",
      "   Restored 600 images...\n",
      "   Restored 500 images...\n",
      "   Restored 600 images...\n",
      "   Restored 700 images...\n",
      "   Restored 800 images...\n",
      "   Restored 700 images...\n",
      "   Restored 800 images...\n",
      "   Restored 900 images...\n",
      "   Restored 1000 images...\n",
      "   Restored 900 images...\n",
      "   Restored 1000 images...\n",
      "   Restored 1100 images...\n",
      "   Restored 1200 images...\n",
      "   Restored 1100 images...\n",
      "   Restored 1200 images...\n",
      "   Restored 1300 images...\n",
      "   Restored 1400 images...\n",
      "   Restored 1500 images...\n",
      "   Restored 1300 images...\n",
      "   Restored 1400 images...\n",
      "   Restored 1500 images...\n",
      "   Restored 1600 images...\n",
      "   Restored 1700 images...\n",
      "   Restored 1600 images...\n",
      "   Restored 1700 images...\n",
      "   Restored 1800 images...\n",
      "   Restored 1900 images...\n",
      "   Restored 1800 images...\n",
      "   Restored 1900 images...\n",
      "   Restored 2000 images...\n",
      "   Restored 2100 images...\n",
      "   Restored 2000 images...\n",
      "   Restored 2100 images...\n",
      "   Restored 2200 images...\n",
      "   Restored 2200 images...\n",
      "   Restored 2300 images...\n",
      "   Restored 2300 images...\n",
      "   Restored 2400 images...\n",
      "   Restored 2400 images...\n",
      "   Restored 2500 images...\n",
      "   Restored 2600 images...\n",
      "   Restored 2500 images...\n",
      "   Restored 2600 images...\n",
      "   Restored 2700 images...\n",
      "   Restored 2800 images...\n",
      "   Restored 2700 images...\n",
      "   Restored 2800 images...\n",
      "   Restored 2900 images...\n",
      "   Restored 3000 images...\n",
      "   Restored 2900 images...\n",
      "   Restored 3000 images...\n",
      "   Restored 3100 images...\n",
      "   Restored 3200 images...\n",
      "   Restored 3100 images...\n",
      "   Restored 3200 images...\n",
      "   Restored 3300 images...\n",
      "   Restored 3400 images...\n",
      "   Restored 3300 images...\n",
      "   Restored 3400 images...\n",
      "   Restored 3500 images...\n",
      "   Restored 3600 images...\n",
      "   Restored 3500 images...\n",
      "   Restored 3600 images...\n",
      "   Restored 3700 images...\n",
      "   Restored 3700 images...\n",
      "   Restored 3800 images...\n",
      "   Restored 3800 images...\n",
      "   Restored 3900 images...\n",
      "   Restored 3900 images...\n",
      "   Restored 4000 images...\n",
      "   Restored 4100 images...\n",
      "   Restored 4000 images...\n",
      "   Restored 4100 images...\n",
      "   Restored 4200 images...\n",
      "   Restored 4300 images...\n",
      "   Restored 4200 images...\n",
      "   Restored 4300 images...\n",
      "   Restored 4400 images...\n",
      "   Restored 4400 images...\n",
      "   Restored 4500 images...\n",
      "   Restored 4600 images...\n",
      "   Restored 4500 images...\n",
      "   Restored 4600 images...\n",
      "   Restored 4700 images...\n",
      "   Restored 4700 images...\n",
      "   Restored 4800 images...\n",
      "   Restored 4800 images...\n",
      "   Restored 4900 images...\n",
      "   Restored 4900 images...\n",
      "   Restored 5000 images...\n",
      "   Restored 5100 images...\n",
      "   Restored 5000 images...\n",
      "   Restored 5100 images...\n",
      "   Restored 5200 images...\n",
      "   Restored 5300 images...\n",
      "   Restored 5200 images...\n",
      "   Restored 5300 images...\n",
      "   Restored 5400 images...\n",
      "   Restored 5500 images...\n",
      "   Restored 5400 images...\n",
      "   Restored 5500 images...\n",
      "   Restored 5600 images...\n",
      "   Restored 5700 images...\n",
      "   Restored 5800 images...\n",
      "   Restored 5600 images...\n",
      "   Restored 5700 images...\n",
      "   Restored 5800 images...\n",
      "   Restored 5900 images...\n",
      "   Restored 6000 images...\n",
      "   Restored 5900 images...\n",
      "   Restored 6000 images...\n",
      "   Restored 6100 images...\n",
      "   Restored 6200 images...\n",
      "   Restored 6100 images...\n",
      "   Restored 6200 images...\n",
      "   Restored 6300 images...\n",
      "   Restored 6400 images...\n",
      "   Restored 6300 images...\n",
      "   Restored 6400 images...\n",
      "   Restored 6500 images...\n",
      "   Restored 6600 images...\n",
      "   Restored 6500 images...\n",
      "   Restored 6600 images...\n",
      "   Restored 6700 images...\n",
      "   Restored 6700 images...\n",
      "   Restored 6800 images...\n",
      "   Restored 6900 images...\n",
      "   Restored 6800 images...\n",
      "   Restored 6900 images...\n",
      "   Restored 7000 images...\n",
      "   Restored 7000 images...\n",
      "   Restored 7100 images...\n",
      "   Restored 7200 images...\n",
      "   Restored 7100 images...\n",
      "   Restored 7200 images...\n",
      "   Restored 7300 images...\n",
      "   Restored 7400 images...\n",
      "   Restored 7300 images...\n",
      "   Restored 7400 images...\n",
      "   Restored 7500 images...\n",
      "   Restored 7500 images...\n",
      "   Restored 7600 images...\n",
      "   Restored 7700 images...\n",
      "   Restored 7600 images...\n",
      "   Restored 7700 images...\n",
      "   Restored 7800 images...\n",
      "   Restored 7800 images...\n",
      "   Restored 7900 images...\n",
      "   Restored 8000 images...\n",
      "   Restored 7900 images...\n",
      "   Restored 8000 images...\n",
      "   Restored 8100 images...\n",
      "   Restored 8100 images...\n",
      "   Restored 8200 images...\n",
      "   Restored 8200 images...\n",
      "   Restored 8300 images...\n",
      "   Restored 8300 images...\n",
      "   Restored 8400 images...\n",
      "   Restored 8400 images...\n",
      "   Restored 8500 images...\n",
      "   Restored 8600 images...\n",
      "   Restored 8500 images...\n",
      "   Restored 8600 images...\n",
      "   Restored 8700 images...\n",
      "   Restored 8700 images...\n",
      "   Restored 8800 images...\n",
      "   Restored 8800 images...\n",
      "   Restored 8900 images...\n",
      "   Restored 8900 images...\n",
      "   Restored 9000 images...\n",
      "   Restored 9100 images...\n",
      "   Restored 9000 images...\n",
      "   Restored 9100 images...\n",
      "   Restored 9200 images...\n",
      "   Restored 9300 images...\n",
      "   Restored 9200 images...\n",
      "   Restored 9300 images...\n",
      "   Restored 9400 images...\n",
      "   Restored 9500 images...\n",
      "   Restored 9400 images...\n",
      "   Restored 9500 images...\n",
      "   Restored 9600 images...\n",
      "   Restored 9700 images...\n",
      "   Restored 9600 images...\n",
      "   Restored 9700 images...\n",
      "   Restored 9800 images...\n",
      "   Restored 9800 images...\n",
      "   Restored 9900 images...\n",
      "   Restored 9900 images...\n",
      "   Restored 10000 images...\n",
      "   Restored 10100 images...\n",
      "   Restored 10000 images...\n",
      "   Restored 10100 images...\n",
      "   Restored 10200 images...\n",
      "   Restored 10200 images...\n",
      "   Restored 10300 images...\n",
      "   Restored 10400 images...\n",
      "   Restored 10500 images...\n",
      "   Restored 10300 images...\n",
      "   Restored 10400 images...\n",
      "   Restored 10500 images...\n",
      "   Restored 10600 images...\n",
      "   Restored 10700 images...\n",
      "   Restored 10600 images...\n",
      "   Restored 10700 images...\n",
      "   Restored 10800 images...\n",
      "   Restored 10900 images...\n",
      "   Restored 10800 images...\n",
      "   Restored 10900 images...\n",
      "   Restored 11000 images...\n",
      "   Restored 11100 images...\n",
      "   Restored 11000 images...\n",
      "   Restored 11100 images...\n",
      "   Restored 11200 images...\n",
      "   Restored 11300 images...\n",
      "   Restored 11200 images...\n",
      "   Restored 11300 images...\n",
      "   Restored 11400 images...\n",
      "   Restored 11500 images...\n",
      "   Restored 11400 images...\n",
      "   Restored 11500 images...\n",
      "   Restored 11600 images...\n",
      "   Restored 11700 images...\n",
      "   Restored 11600 images...\n",
      "   Restored 11700 images...\n",
      "   Restored 11800 images...\n",
      "   Restored 11900 images...\n",
      "   Restored 12000 images...\n",
      "   Restored 11800 images...\n",
      "   Restored 11900 images...\n",
      "   Restored 12000 images...\n",
      "   Restored 12100 images...\n",
      "   Restored 12200 images...\n",
      "   Restored 12100 images...\n",
      "   Restored 12200 images...\n",
      "   Restored 12300 images...\n",
      "   Restored 12400 images...\n",
      "   Restored 12300 images...\n",
      "   Restored 12400 images...\n",
      "   Restored 12500 images...\n",
      "   Restored 12600 images...\n",
      "   Restored 12500 images...\n",
      "   Restored 12600 images...\n",
      "   Restored 12700 images...\n",
      "   Restored 12800 images...\n",
      "   Restored 12700 images...\n",
      "   Restored 12800 images...\n",
      "   Restored 12900 images...\n",
      "   Restored 13000 images...\n",
      "   Restored 12900 images...\n",
      "   Restored 13000 images...\n",
      "   Restored 13100 images...\n",
      "   Restored 13200 images...\n",
      "   Restored 13100 images...\n",
      "   Restored 13200 images...\n",
      "‚úÖ Restored 13233 images to their subdirectories\n",
      "‚úÖ Restored 13233 images to their subdirectories\n",
      "üìä Total images in negative folder (including subdirectories): 13233\n",
      "üìÅ Restored 2280 person folders\n",
      "   First 5 folders: ['Aaron', 'Abba', 'Abbas', 'Abdel', 'Abdoulaye']\n",
      "üìä Total images in negative folder (including subdirectories): 13233\n",
      "üìÅ Restored 2280 person folders\n",
      "   First 5 folders: ['Aaron', 'Abba', 'Abbas', 'Abdel', 'Abdoulaye']\n"
     ]
    }
   ],
   "source": [
    "### Revert: Restore negative folder structure\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import re\n",
    "\n",
    "print(\"üîÑ Restoring negative folder structure...\")\n",
    "\n",
    "# Find all flattened images (they have person name prefix)\n",
    "flattened_images = glob.glob(os.path.join(NEG_Path, '*_*.jpg'))\n",
    "restored_count = 0\n",
    "\n",
    "for img_path in flattened_images:\n",
    "    filename = os.path.basename(img_path)\n",
    "    \n",
    "    # Extract person name from filename (everything before the first underscore of the original name)\n",
    "    # Pattern: PersonName_OriginalFilename.jpg\n",
    "    # We need to extract the person name that was added as prefix\n",
    "    \n",
    "    # Split by underscore and reconstruct\n",
    "    parts = filename.split('_')\n",
    "    \n",
    "    if len(parts) >= 2:\n",
    "        # The person name is the first part\n",
    "        person_name = parts[0]\n",
    "        \n",
    "        # Original filename is everything after first underscore\n",
    "        original_filename = '_'.join(parts[1:])\n",
    "        \n",
    "        # Create person subdirectory if it doesn't exist\n",
    "        person_dir = os.path.join(NEG_Path, person_name)\n",
    "        os.makedirs(person_dir, exist_ok=True)\n",
    "        \n",
    "        # Move file back to subdirectory\n",
    "        new_path = os.path.join(person_dir, original_filename)\n",
    "        \n",
    "        try:\n",
    "            shutil.move(img_path, new_path)\n",
    "            restored_count += 1\n",
    "            if restored_count % 100 == 0:\n",
    "                print(f\"   Restored {restored_count} images...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error restoring {filename}: {e}\")\n",
    "\n",
    "print(f\"‚úÖ Restored {restored_count} images to their subdirectories\")\n",
    "\n",
    "# Count images in subdirectories\n",
    "total_in_subdirs = len(glob.glob(os.path.join(NEG_Path, '**', '*.jpg'), recursive=True))\n",
    "print(f\"üìä Total images in negative folder (including subdirectories): {total_in_subdirs}\")\n",
    "\n",
    "# Show restored structure\n",
    "subdirs = [d for d in os.listdir(NEG_Path) if os.path.isdir(os.path.join(NEG_Path, d))]\n",
    "print(f\"üìÅ Restored {len(subdirs)} person folders\")\n",
    "if len(subdirs) > 0:\n",
    "    print(f\"   First 5 folders: {subdirs[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1b1fac",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7c2f1a",
   "metadata": {},
   "source": [
    "- we are going to write a function that loads an image from the directory, resize it and perform scaling on it. \n",
    "- we are going to convert all of our image values from 0-255 to 0-1. And this helps our neural network optimize easier and better as it makes the gradient descent a little bit easier hence a better performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a49bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    # we are passing the file path as the path given above to the preprocess function. \n",
    "    byte_img=tf.io.read_file(file_path) # this reads the image from the path\n",
    "    img = tf.io.decode_jpeg(byte_img) # this decodes the image into a tensor\n",
    "    #this is preprocessing the image from here\n",
    "    img=tf.image.resize(img, (100,100)) \n",
    "    img=img/255.0 #scale the image by taking the original image and dividing it by 255 to make the image be between 0-1.\n",
    "    return img\n",
    "#what this function does is that it takes in the filepath of an image and returns the numpy equivalent of the image after resizing and scaling it.\n",
    "#we also come to learn that the min value of the numpy is 0 and the max value is 1.0\n",
    "\n",
    "#in short we take an image from a directory as we did in the tf.data.Dataset.list_files method and we read it, decode it, resize it and scale it to be between 0 and 1.0 as it helps to reduce the gradient descent and reduce our computation of our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c200bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# here we are creating our labelled dataset of twins or tuplets because \n",
    "# we shall be passing two labels at the same time.\n",
    "\n",
    "# Get the cardinality (length) of datasets properly\n",
    "anchor_len = tf.data.experimental.cardinality(anchor).numpy()\n",
    "positive_len = tf.data.experimental.cardinality(positive).numpy()\n",
    "negative_len = tf.data.experimental.cardinality(negative).numpy()\n",
    "\n",
    "# Make sure we have matching lengths by taking the minimum\n",
    "min_len = min(anchor_len, positive_len, negative_len)\n",
    "\n",
    "print(f\"Creating labelled dataset with {min_len} samples of each type...\")\n",
    "\n",
    "# Take the same number of samples from each dataset\n",
    "anchor_trimmed = anchor.take(min_len)\n",
    "positive_trimmed = positive.take(min_len)\n",
    "negative_trimmed = negative.take(min_len)\n",
    "\n",
    "# Create positive pairs (anchor, positive, label=1)\n",
    "positives = tf.data.Dataset.zip((\n",
    "    anchor_trimmed, \n",
    "    positive_trimmed, \n",
    "    tf.data.Dataset.from_tensor_slices(tf.ones(min_len))\n",
    "))\n",
    "\n",
    "# Create negative pairs (anchor, negative, label=0)\n",
    "negatives = tf.data.Dataset.zip((\n",
    "    anchor_trimmed, \n",
    "    negative_trimmed, \n",
    "    tf.data.Dataset.from_tensor_slices(tf.zeros(min_len))\n",
    "))\n",
    "\n",
    "# Combine positive and negative samples\n",
    "data = positives.concatenate(negatives)\n",
    "\n",
    "# Test the data pipeline\n",
    "sample = data.as_numpy_iterator()\n",
    "example = sample.next()\n",
    "print(\"\\n‚úÖ Sample data structure:\", example)\n",
    "print(f\"   - Anchor path: {example[0]}\")\n",
    "print(f\"   - Comparison path: {example[1]}\")\n",
    "print(f\"   - Label: {example[2]} (1=positive pair, 0=negative pair)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6cad4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'C:\\\\Projects\\\\EDUFACE PROJECT\\\\students_faces_dataset\\\\benjamin_mbeva_151541\\\\benjamin_mbeva_151541_front2_12.jpg', b'C:\\\\Projects\\\\EDUFACE PROJECT\\\\students_faces_dataset\\\\benjamin_mbeva_151541\\\\benjamin_mbeva_151541_front2_12.jpg', np.float32(1.0))\n"
     ]
    }
   ],
   "source": [
    "sample=data.as_numpy_iterator()\n",
    "example = sample.next()\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92d6a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we are just going to use our preprocess function to preprocess these directories so that rather than just having the file paths we have the actual images that we can use to train our model. and we also have our label either 0 or 1\n",
    "# now we are going to write our second function that we will preprocess a twin (negative and positive) image along with the label.\n",
    "\n",
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return (preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3be171ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
       " array([[[0.9752451 , 0.00441176, 0.96568626],\n",
       "         [0.93088233, 0.03480392, 0.910049  ],\n",
       "         [0.9279412 , 0.04558824, 0.9252451 ],\n",
       "         ...,\n",
       "         [0.9115196 , 0.04338235, 0.9012255 ],\n",
       "         [0.9139706 , 0.04117647, 0.90931374],\n",
       "         [0.95637256, 0.02009804, 0.9470588 ]],\n",
       " \n",
       "        [[0.9338235 , 0.03676471, 0.9227941 ],\n",
       "         [0.96617645, 0.5151961 , 0.925     ],\n",
       "         [0.87009805, 0.59362745, 0.8220588 ],\n",
       "         ...,\n",
       "         [0.8879902 , 0.6357843 , 0.83455884],\n",
       "         [0.91593134, 0.62009805, 0.84632355],\n",
       "         [0.9627451 , 0.2504902 , 0.92058825]],\n",
       " \n",
       "        [[0.93578434, 0.04926471, 0.92965686],\n",
       "         [0.8781863 , 0.59632355, 0.8120098 ],\n",
       "         [0.69166666, 0.6647059 , 0.6134804 ],\n",
       "         ...,\n",
       "         [0.78357846, 0.7588235 , 0.7115196 ],\n",
       "         [0.79338235, 0.7615196 , 0.7019608 ],\n",
       "         [0.9129902 , 0.30269608, 0.86960787]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.9073529 , 0.04705882, 0.922549  ],\n",
       "         [0.7056373 , 0.46838236, 0.7477941 ],\n",
       "         [0.5764706 , 0.5803922 , 0.62941176],\n",
       "         ...,\n",
       "         [0.75490195, 0.31936276, 0.3348039 ],\n",
       "         [0.7438725 , 0.32230392, 0.32230392],\n",
       "         [0.9120098 , 0.12352941, 0.70980394]],\n",
       " \n",
       "        [[0.92083335, 0.04117647, 0.922549  ],\n",
       "         [0.70686275, 0.46078432, 0.7470588 ],\n",
       "         [0.5735294 , 0.5737745 , 0.60343134],\n",
       "         ...,\n",
       "         [0.76740193, 0.31960785, 0.3227941 ],\n",
       "         [0.77254903, 0.31446078, 0.3409314 ],\n",
       "         [0.9073529 , 0.12818627, 0.72205883]],\n",
       " \n",
       "        [[0.9705882 , 0.02205882, 0.95686275],\n",
       "         [0.87009805, 0.19240196, 0.8715686 ],\n",
       "         [0.8156863 , 0.22720589, 0.8301471 ],\n",
       "         ...,\n",
       "         [0.9169118 , 0.12941177, 0.7247549 ],\n",
       "         [0.89705884, 0.14093137, 0.7088235 ],\n",
       "         [0.9602941 , 0.0497549 , 0.8629902 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
       " array([[[0.9752451 , 0.00441176, 0.96568626],\n",
       "         [0.93088233, 0.03480392, 0.910049  ],\n",
       "         [0.9279412 , 0.04558824, 0.9252451 ],\n",
       "         ...,\n",
       "         [0.9115196 , 0.04338235, 0.9012255 ],\n",
       "         [0.9139706 , 0.04117647, 0.90931374],\n",
       "         [0.95637256, 0.02009804, 0.9470588 ]],\n",
       " \n",
       "        [[0.9338235 , 0.03676471, 0.9227941 ],\n",
       "         [0.96617645, 0.5151961 , 0.925     ],\n",
       "         [0.87009805, 0.59362745, 0.8220588 ],\n",
       "         ...,\n",
       "         [0.8879902 , 0.6357843 , 0.83455884],\n",
       "         [0.91593134, 0.62009805, 0.84632355],\n",
       "         [0.9627451 , 0.2504902 , 0.92058825]],\n",
       " \n",
       "        [[0.93578434, 0.04926471, 0.92965686],\n",
       "         [0.8781863 , 0.59632355, 0.8120098 ],\n",
       "         [0.69166666, 0.6647059 , 0.6134804 ],\n",
       "         ...,\n",
       "         [0.78357846, 0.7588235 , 0.7115196 ],\n",
       "         [0.79338235, 0.7615196 , 0.7019608 ],\n",
       "         [0.9129902 , 0.30269608, 0.86960787]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.9073529 , 0.04705882, 0.922549  ],\n",
       "         [0.7056373 , 0.46838236, 0.7477941 ],\n",
       "         [0.5764706 , 0.5803922 , 0.62941176],\n",
       "         ...,\n",
       "         [0.75490195, 0.31936276, 0.3348039 ],\n",
       "         [0.7438725 , 0.32230392, 0.32230392],\n",
       "         [0.9120098 , 0.12352941, 0.70980394]],\n",
       " \n",
       "        [[0.92083335, 0.04117647, 0.922549  ],\n",
       "         [0.70686275, 0.46078432, 0.7470588 ],\n",
       "         [0.5735294 , 0.5737745 , 0.60343134],\n",
       "         ...,\n",
       "         [0.76740193, 0.31960785, 0.3227941 ],\n",
       "         [0.77254903, 0.31446078, 0.3409314 ],\n",
       "         [0.9073529 , 0.12818627, 0.72205883]],\n",
       " \n",
       "        [[0.9705882 , 0.02205882, 0.95686275],\n",
       "         [0.87009805, 0.19240196, 0.8715686 ],\n",
       "         [0.8156863 , 0.22720589, 0.8301471 ],\n",
       "         ...,\n",
       "         [0.9169118 , 0.12941177, 0.7247549 ],\n",
       "         [0.89705884, 0.14093137, 0.7088235 ],\n",
       "         [0.9602941 , 0.0497549 , 0.8629902 ]]], dtype=float32)>,\n",
       " np.float32(1.0))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_twin(*example) #we are grabbing one example out of our data iteratator and passing it to our preprocess twin function to see if it works and the star is used to unpack the example tuple that we had above.\n",
    "\n",
    "#it has 3 things. i.e. \n",
    "#. 1, is the preprocessed anchor image and can be seen from the output 100 by 100 by 3 channels as below. \n",
    "#2. is the preprocessed positive or negative image depending on what we passed and it also has the same shape as the anchor image\n",
    "#3. is the label either 0 or 1 depending on what we passed.\n",
    "\n",
    "#now we are going to map our data using the preprocess_twin function that we created above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae9f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are going to map our data using the preprocess_twin function that we created above.\n",
    "\n",
    "# Build the data pipeline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()  # caching the data so that it is not reloaded every time we are training our model\n",
    "data = data.shuffle(buffer_size=1024)  # shuffling the data so we don't have all positive samples first then negative\n",
    "data = data.batch(16)  # batching the data so we can train in batches rather than one by one\n",
    "data = data.prefetch(8)  # prefetch data for better performance\n",
    "\n",
    "print(f\"\\n‚úÖ Data pipeline built successfully!\")\n",
    "print(f\"   - Preprocessing: resize to 100x100, scale to 0-1\")\n",
    "print(f\"   - Cached: Yes\")\n",
    "print(f\"   - Shuffled: Yes (buffer=1024)\")\n",
    "print(f\"   - Batch size: 16\")\n",
    "print(f\"   - Total batches: ~{tf.data.experimental.cardinality(data).numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d63ff0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "samples = data.as_numpy_iterator()\n",
    "\n",
    "# Get one batch of data\n",
    "batch = samples.next()\n",
    "\n",
    "# Each batch has 3 parts: (anchor, positive/negative, label)\n",
    "anchor, positive, label = batch\n",
    "\n",
    "# Display one image from the anchor batch (e.g., first image)\n",
    "plt.imshow(anchor[0])  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a7ca7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp=samples.next()\n",
    "samp[2]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
