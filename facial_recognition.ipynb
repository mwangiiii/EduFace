{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb803301",
   "metadata": {},
   "source": [
    "# EDUFACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd233fba",
   "metadata": {},
   "source": [
    "-    this is a facial recognition system that will be integrated together with an LMS system to record student's attendance using facial recognition technology integrated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50233524",
   "metadata": {},
   "source": [
    "### INSTALLING THE DEPENDENCIES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73b16457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\projects\\eduface project\\venv\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: opencv-python in c:\\projects\\eduface project\\venv\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: matplotlib in c:\\projects\\eduface project\\venv\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (1.73.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: setuptools in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: packaging in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\projects\\eduface project\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\projects\\eduface project\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\projects\\eduface project\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\projects\\eduface project\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow opencv-python matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5889d05",
   "metadata": {},
   "source": [
    "### IMPORTING THE DEPENDENCIES.\n",
    "\n",
    "- we will install the standard dependencies first then install the tensor-flow dependencies later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11097e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#isntalling standard dependencies.\n",
    "\n",
    "import cv2 #used to import open-cv into the noteboook\n",
    "import os #OS system library that is needed when creating our Directories. it hence abstracts our operating system from our python\n",
    "import random #used if we are generating new data.\n",
    "import numpy as np #used when working with mathematical operations.\n",
    "from matplotlib import pyplot as plt #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63c225b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will now import tensorflow dependencies that will use tensorflow functional API components.\n",
    "from tensorflow.keras.models import Model #this is one of most important layers since when creating a model we will need this when declaring Model(Inputs=>>> Output=>>) it enables us classify betwen output and input.\n",
    "#our model will  look like: Model(inputs=[inputImage, verificationImage] output=[1,0]) this is what the model class helps us to do.\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten #model is a whole lot of abig class and we need these specific classes when building our model\n",
    "#1. layer class is a high level class that helps you define a custom neural network layer\n",
    "#2. conv2d - allows us to perform convolutions\n",
    "#3. dense allows us to get a fully connected layer\n",
    "#4. maxpooling2D allows us to pull our layers together and combine the information that we have through a condition\n",
    "#5. Input allows us to identofy what we are passing through to our model.\n",
    "#6. flatten takes the information from  a previous layer and flatten it into a single dimension\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5161f99",
   "metadata": {},
   "source": [
    "### Set GPU growth.\n",
    "- here we are going to limit our amount of VRAM given to tensorflow hence you will keep on ending up to \"out of memory error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63014504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "print(\"Number of GPUs available:\", len(gpus))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9174ac28",
   "metadata": {},
   "source": [
    "### Setting up folder structure.\n",
    "- we are going to set up the directories for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cea780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_Path=os.path.join('data', 'positive')\n",
    "NEG_Path=os.path.join('data', 'negative')\n",
    "ANC_Path=os.path.join('data', 'anchor')\n",
    "\n",
    "#the above create the paths for the directories.\n",
    "\n",
    "#os.path.join joins diferent directroy together to be able to get a full file path and you will be able to get  forward backslash or backward slash depeding on the Os that you are using\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3936d050",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'data\\\\positive'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Mke the actual directories specified with the above paths\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPOS_Path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(NEG_Path)\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(ANC_Path)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'data\\\\positive'"
     ]
    }
   ],
   "source": [
    "\n",
    "#Mke the actual directories specified with the above paths\n",
    "os.makedirs(POS_Path)\n",
    "os.makedirs(NEG_Path)\n",
    "os.makedirs(ANC_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f601765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ Dataset already extracted at: C:\\Projects\\EDUFACE PROJECT\\lfw\n",
      "Number of persons in dataset: 0\n",
      "First 5 persons: []\n"
     ]
    }
   ],
   "source": [
    "import tarfile  # For .tgz files\n",
    "import os\n",
    "\n",
    "# 1. Path to your LFW .tgz file in your local filesystem\n",
    "tgz_path = r\"C:\\Projects\\EDUFACE PROJECT\\lfw-funneled.tgz\"  # 👈 Adjust to the actual path of lfw-funneled.tgz\n",
    "\n",
    "# 2. Extraction path (where the dataset will be extracted)\n",
    "extract_path = r\"C:\\Projects\\EDUFACE PROJECT\\lfw\"  # 👈 Adjust as needed for your local filesystem\n",
    "\n",
    "# 3. Validate the .tgz file exists\n",
    "if not os.path.isfile(tgz_path):\n",
    "    raise FileNotFoundError(f\"Error: The file '{tgz_path}' does not exist or is not a file.\")\n",
    "\n",
    "# 4. Extract only if not already extracted\n",
    "if not os.path.exists(extract_path):\n",
    "    os.makedirs(extract_path, exist_ok=True)\n",
    "    try:\n",
    "        with tarfile.open(tgz_path, 'r:gz') as tar:\n",
    "            tar.extractall(path=extract_path)\n",
    "        print(\"✅ Dataset extracted successfully at:\", extract_path)\n",
    "    except PermissionError:\n",
    "        raise PermissionError(f\"Error: Permission denied when accessing '{tgz_path}' or '{extract_path}'. Check file/folder permissions.\")\n",
    "    except tarfile.ReadError:\n",
    "        raise ValueError(f\"Error: '{tgz_path}' is not a valid .tgz file.\")\n",
    "else:\n",
    "    print(\"ℹ️ Dataset already extracted at:\", extract_path)\n",
    "\n",
    "lfw_root = os.path.join(extract_path, \"lfw_funneled\")\n",
    "\n",
    "# 5. Quick check of structure\n",
    "if os.path.exists(lfw_root):\n",
    "    print(\"Number of persons in dataset:\", len(os.listdir(lfw_root)))\n",
    "    print(\"First 5 persons:\", os.listdir(lfw_root)[:5])\n",
    "else:\n",
    "    print(f\"Error: The directory '{lfw_root}' does not exist. Extraction may have failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e26596",
   "metadata": {},
   "source": [
    "### moving the lfw data into the data/negative data repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f10649",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for directory in os.listdir('lfw'):\n",
    "  for file in os.listdir(os.path.join('lfw', directory)):\n",
    "    EX_PATH=os.path.join('lfw', directory, file)\n",
    "    NEW_PATH=os.path.join(NEG_Path, file)\n",
    "    os.replace(EX_PATH, NEW_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319024c",
   "metadata": {},
   "source": [
    "## collect Positves and Anchors.\n",
    "- we are going to use opencv and we are going to collect those images down nd save them down. the sime of the images to be collected are going to be 250 pixels by 250 pixels.\n",
    "\n",
    "-   by default, when using webcam, the resolution of the images might be a little different so we should ensure that we are collecting images of that size because the sizes from the training dataset are of the same size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba77639f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading face detection cascades...\n",
      "✅ Loaded frontal cascade\n",
      "✅ Loaded profile cascade\n",
      "✅ Loaded frontal_alt cascade\n",
      "✅ Loaded frontal_alt2 cascade\n",
      "Testing Index 0, Backend default: Opened=True, Frame captured=True\n",
      "✅ Webcam found at index 0 (backend: default)\n",
      "\n",
      "👉 Using source: index 0\n",
      "👉 A video preview window will appear.\n",
      "👉 Press and hold 'c' to capture images continuously (every 0.2s).\n",
      "👉 The system will detect faces from multiple angles (front, profile, etc.)\n",
      "👉 Release 'c' to pause. Press and hold again to continue capturing.\n",
      "👉 Press 'q' to quit and save all captured images.\n",
      "⚠️ Images will be cropped to detected faces and saved with angle information.\n",
      "\n",
      "💡 TIP: Move your head to different angles while capturing for a better dataset!\n",
      "   - Look straight at camera (frontal)\n",
      "   - Turn left and right (profiles)\n",
      "   - Slightly tilt up and down\n",
      "\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front_41.jpg (Type: frontal_alt)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front2_42.jpg (Type: frontal_alt2)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_43.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_44.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_45.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_46.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_47.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_48.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_49.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front_50.jpg (Type: frontal)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_51.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_52.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front_53.jpg (Type: frontal)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front_54.jpg (Type: frontal)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_55.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_56.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_57.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_58.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_59.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_60.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_61.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_62.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front_63.jpg (Type: frontal_alt)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front2_64.jpg (Type: frontal_alt2)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front2_65.jpg (Type: frontal_alt2)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front_66.jpg (Type: frontal_alt)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front_67.jpg (Type: frontal_alt)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front2_68.jpg (Type: frontal_alt2)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front_69.jpg (Type: frontal)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front2_70.jpg (Type: frontal_alt2)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front2_71.jpg (Type: frontal_alt2)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_72.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_73.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_74.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_75.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front_76.jpg (Type: frontal_alt)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front2_77.jpg (Type: frontal_alt2)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front2_78.jpg (Type: frontal_alt2)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front_79.jpg (Type: frontal_alt)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front2_80.jpg (Type: frontal_alt2)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front2_81.jpg (Type: frontal_alt2)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_front2_82.jpg (Type: frontal_alt2)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_83.jpg (Type: profile)\n",
      "✅ Saved C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\\dennis_151354\\dennis_151354_profile_84.jpg (Type: profile)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import platform\n",
    "\n",
    "def find_working_webcam(max_index=10):\n",
    "    \"\"\"Try to find a working webcam by testing indices with optional backend.\"\"\"\n",
    "    backends = [None]  # Default backend\n",
    "    if platform.system() == \"Windows\":\n",
    "        backends.append(cv2.CAP_DSHOW)  # DirectShow\n",
    "        backends.append(cv2.CAP_MSMF)   # Windows Media Foundation\n",
    "    elif platform.system() == \"Linux\":\n",
    "        backends.append(cv2.CAP_V4L2)   # V4L2\n",
    "\n",
    "    for backend in backends:\n",
    "        for index in range(max_index):\n",
    "            cap = cv2.VideoCapture(index, backend) if backend else cv2.VideoCapture(index)\n",
    "            if cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                print(f\"Testing Index {index}, Backend {backend if backend else 'default'}: Opened={cap.isOpened()}, Frame captured={ret}\")\n",
    "                if ret:\n",
    "                    print(f\"✅ Webcam found at index {index} (backend: {backend if backend else 'default'})\")\n",
    "                    return cap, index\n",
    "                cap.release()\n",
    "    return None, None\n",
    "\n",
    "# Fallback: Use a video file or static image for debugging if no webcam is found\n",
    "fallback_source = r\"C:\\Projects\\EDUFACE PROJECT\\test_video.mp4\"  # Replace with a video/image path\n",
    "\n",
    "# Ask for student details\n",
    "student_name = input(\"Enter student name: \").strip().replace(\" \", \"_\")\n",
    "student_id = input(\"Enter school ID: \").strip()\n",
    "\n",
    "# Validate student_id for safe file naming\n",
    "invalid_chars = '<>:\"/\\\\|?*'\n",
    "for char in invalid_chars:\n",
    "    student_id = student_id.replace(char, \"_\")\n",
    "\n",
    "# Create dataset folder\n",
    "dataset_folder = r\"C:\\Projects\\EDUFACE PROJECT\\students_faces_dataset\"\n",
    "os.makedirs(dataset_folder, exist_ok=True)\n",
    "\n",
    "# Create sub-folder for this student\n",
    "folder_name = os.path.join(dataset_folder, f\"{student_name}_{student_id}\")\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Determine starting count based on existing files\n",
    "existing_files = glob.glob(os.path.join(folder_name, f\"{student_name}_{student_id}_*.jpg\"))\n",
    "if existing_files:\n",
    "    counts = []\n",
    "    for f in existing_files:\n",
    "        try:\n",
    "            # Extract number from filename (handle both frame and angle naming)\n",
    "            basename = os.path.basename(f)\n",
    "            if 'frame' in basename:\n",
    "                num = int(basename.split('frame')[1].split('.jpg')[0])\n",
    "            else:\n",
    "                # For angle-based naming like \"front_1.jpg\", \"left_2.jpg\", etc.\n",
    "                parts = basename.replace(f\"{student_name}_{student_id}_\", \"\").replace(\".jpg\", \"\")\n",
    "                if '_' in parts:\n",
    "                    num = int(parts.split('_')[-1])\n",
    "                else:\n",
    "                    num = 1\n",
    "            counts.append(num)\n",
    "        except:\n",
    "            continue\n",
    "    count = max(counts) + 1 if counts else 1\n",
    "else:\n",
    "    count = 1\n",
    "\n",
    "# Load multiple Haar Cascades for different face orientations\n",
    "cascades = {}\n",
    "cascade_files = {\n",
    "    'frontal': 'haarcascade_frontalface_default.xml',\n",
    "    'profile': 'haarcascade_profileface.xml',\n",
    "    'frontal_alt': 'haarcascade_frontalface_alt.xml',\n",
    "    'frontal_alt2': 'haarcascade_frontalface_alt2.xml'\n",
    "}\n",
    "\n",
    "print(\"Loading face detection cascades...\")\n",
    "for cascade_name, cascade_file in cascade_files.items():\n",
    "    cascade_path = cv2.data.haarcascades + cascade_file\n",
    "    cascade = cv2.CascadeClassifier(cascade_path)\n",
    "    if not cascade.empty():\n",
    "        cascades[cascade_name] = cascade\n",
    "        print(f\"✅ Loaded {cascade_name} cascade\")\n",
    "    else:\n",
    "        print(f\"⚠️ Could not load {cascade_name} cascade from {cascade_path}\")\n",
    "\n",
    "if not cascades:\n",
    "    raise ValueError(\"Error: Could not load any Haar Cascade classifiers.\")\n",
    "\n",
    "def detect_faces_multi_angle(gray_frame):\n",
    "    \"\"\"Detect faces using multiple cascades for different angles\"\"\"\n",
    "    all_faces = []\n",
    "    detected_types = []\n",
    "    \n",
    "    for cascade_name, cascade in cascades.items():\n",
    "        # Different parameters for different cascade types\n",
    "        if 'profile' in cascade_name:\n",
    "            faces = cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=4, minSize=(30, 30))\n",
    "        else:\n",
    "            faces = cascade.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "        \n",
    "        for face in faces:\n",
    "            all_faces.append(face)\n",
    "            detected_types.append(cascade_name)\n",
    "    \n",
    "    return all_faces, detected_types\n",
    "\n",
    "def remove_overlapping_faces(faces, detected_types, overlap_threshold=0.3):\n",
    "    \"\"\"Remove overlapping face detections to avoid duplicates\"\"\"\n",
    "    if len(faces) <= 1:\n",
    "        return faces, detected_types\n",
    "    \n",
    "    def calculate_overlap(box1, box2):\n",
    "        x1, y1, w1, h1 = box1\n",
    "        x2, y2, w2, h2 = box2\n",
    "        \n",
    "        # Calculate intersection area\n",
    "        x_overlap = max(0, min(x1 + w1, x2 + w2) - max(x1, x2))\n",
    "        y_overlap = max(0, min(y1 + h1, y2 + h2) - max(y1, y2))\n",
    "        intersection = x_overlap * y_overlap\n",
    "        \n",
    "        # Calculate union area\n",
    "        area1 = w1 * h1\n",
    "        area2 = w2 * h2\n",
    "        union = area1 + area2 - intersection\n",
    "        \n",
    "        return intersection / union if union > 0 else 0\n",
    "    \n",
    "    # Keep track of which faces to keep\n",
    "    keep = [True] * len(faces)\n",
    "    \n",
    "    for i in range(len(faces)):\n",
    "        if not keep[i]:\n",
    "            continue\n",
    "        for j in range(i + 1, len(faces)):\n",
    "            if not keep[j]:\n",
    "                continue\n",
    "            \n",
    "            overlap = calculate_overlap(faces[i], faces[j])\n",
    "            if overlap > overlap_threshold:\n",
    "                # Keep the larger face detection\n",
    "                area1 = faces[i][2] * faces[i][3]\n",
    "                area2 = faces[j][2] * faces[j][3]\n",
    "                if area1 >= area2:\n",
    "                    keep[j] = False\n",
    "                else:\n",
    "                    keep[i] = False\n",
    "                    break\n",
    "    \n",
    "    filtered_faces = [faces[i] for i in range(len(faces)) if keep[i]]\n",
    "    filtered_types = [detected_types[i] for i in range(len(detected_types)) if keep[i]]\n",
    "    \n",
    "    return filtered_faces, filtered_types\n",
    "\n",
    "# Initialize webcam\n",
    "cap, webcam_index = find_working_webcam(max_index=10)\n",
    "if cap is None:\n",
    "    print(\"⚠️ No webcam found. Falling back to test source (video/image) for debugging.\")\n",
    "    if os.path.exists(fallback_source):\n",
    "        cap = cv2.VideoCapture(fallback_source)\n",
    "        webcam_index = \"fallback\"\n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Error: Could not open fallback source '{fallback_source}'.\")\n",
    "        print(f\"Using fallback source: {fallback_source}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Error: No webcam found, and fallback source '{fallback_source}' does not exist.\")\n",
    "\n",
    "print(f\"\\n👉 Using source: index {webcam_index if webcam_index != 'fallback' else fallback_source}\")\n",
    "print(\"👉 A video preview window will appear.\")\n",
    "print(\"👉 Press and hold 'c' to capture images continuously (every 0.2s).\")\n",
    "print(\"👉 The system will detect faces from multiple angles (front, profile, etc.)\")\n",
    "print(\"👉 Release 'c' to pause. Press and hold again to continue capturing.\")\n",
    "print(\"👉 Press 'q' to quit and save all captured images.\")\n",
    "print(\"⚠️ Images will be cropped to detected faces and saved with angle information.\\n\")\n",
    "print(\"💡 TIP: Move your head to different angles while capturing for a better dataset!\")\n",
    "print(\"   - Look straight at camera (frontal)\")\n",
    "print(\"   - Turn left and right (profiles)\")\n",
    "print(\"   - Slightly tilt up and down\\n\")\n",
    "\n",
    "# Flag to control capturing\n",
    "is_capturing = False\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            if webcam_index == \"fallback\" and cap.get(cv2.CAP_PROP_POS_FRAMES) >= cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Loop video\n",
    "                continue\n",
    "            print(\"Error: Failed to capture frame from source.\")\n",
    "            break\n",
    "\n",
    "        # Convert to grayscale for face detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces from multiple angles\n",
    "        faces, face_types = detect_faces_multi_angle(gray)\n",
    "        \n",
    "        # Remove overlapping detections\n",
    "        faces, face_types = remove_overlapping_faces(faces, face_types)\n",
    "\n",
    "        # Draw rectangles around detected faces with different colors for different types\n",
    "        colors = {\n",
    "            'frontal': (0, 255, 0),      # Green for frontal\n",
    "            'profile': (255, 0, 0),      # Blue for profile\n",
    "            'frontal_alt': (0, 255, 255), # Yellow for frontal alt\n",
    "            'frontal_alt2': (255, 0, 255) # Magenta for frontal alt2\n",
    "        }\n",
    "        \n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "            face_type = face_types[i] if i < len(face_types) else 'frontal'\n",
    "            color = colors.get(face_type, (0, 255, 0))\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "            \n",
    "            # Add label showing the detection type\n",
    "            label = face_type.replace('_', ' ').title()\n",
    "            cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        # Add status text\n",
    "        status_text = f\"Faces detected: {len(faces)} | {'CAPTURING' if is_capturing else 'PAUSED'}\"\n",
    "        cv2.putText(frame, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 1)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Multi-Angle Face Capture - Press 'c' to capture, 'q' to quit\", frame)\n",
    "\n",
    "        # Check for keypress\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\n",
    "\n",
    "#collect the anchor images.\n",
    "        if key==ord('a'):\n",
    "            capture_type = 'anchor'\n",
    "            print(\"switched to anchor capture\")\n",
    "        elif key == ord('p'):\n",
    "            capture_type=\"positive\"\n",
    "            print(\"supposed to save positive images\")\n",
    "\n",
    "        elif key == ord('c'):\n",
    "            is_capturing = True\n",
    "        elif key == 255:  # No key pressed (equivalent to releasing 'c')\n",
    "            is_capturing = False\n",
    "        \n",
    "        elif key == ord('q'):\n",
    "            print(\"\\n👋 Exiting capture...\")\n",
    "            break\n",
    "\n",
    "        # Capture and save faces if 'c' is held\n",
    "        if is_capturing and faces:\n",
    "            for i, (x, y, w, h) in enumerate(faces):\n",
    "                face_crop = frame[y:y+h, x:x+w]\n",
    "                \n",
    "                # Determine angle/type for filename\n",
    "                face_type = face_types[i] if i < len(face_types) else 'frontal'\n",
    "                angle_name = face_type.replace('frontal', 'front').replace('_alt', '').replace('_alt2', '')\n",
    "                \n",
    "                # Create filename with angle information\n",
    "                filename = os.path.join(folder_name, f\"{student_name}_{student_id}_{angle_name}_{count}.jpg\")\n",
    "                \n",
    "                # Resize face crop to standard size (optional, good for training)\n",
    "                face_resized = cv2.resize(face_crop, (250, 250))\n",
    "                \n",
    "                cv2.imwrite(filename, face_resized)\n",
    "                print(f\"✅ Saved {filename} (Type: {face_type})\")\n",
    "                count += 1\n",
    "            \n",
    "            time.sleep(0.2)  # Capture every 0.2 seconds to avoid oversaving\n",
    "\n",
    "finally:\n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"\\n👋 Capture session complete. Total images saved: {count - 1}\")\n",
    "print(f\"📁 Images saved in: {folder_name}\")\n",
    "print(\"\\n📊 Dataset Summary:\")\n",
    "# Count different types of images saved\n",
    "angle_counts = {}\n",
    "for f in glob.glob(os.path.join(folder_name, f\"{student_name}_{student_id}_*.jpg\")):\n",
    "    basename = os.path.basename(f)\n",
    "    if 'front' in basename:\n",
    "        angle_counts['frontal'] = angle_counts.get('frontal', 0) + 1\n",
    "    elif 'profile' in basename:\n",
    "        angle_counts['profile'] = angle_counts.get('profile', 0) + 1\n",
    "    else:\n",
    "        angle_counts['other'] = angle_counts.get('other', 0) + 1\n",
    "\n",
    "for angle, count in angle_counts.items():\n",
    "    print(f\"   - {angle.title()}: {count} images\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81408ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
